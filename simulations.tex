%!TEX root=./main.tex
\section{Simulations}

Our experiments apply the feedback alignment algorithm to two-layer networks, using a range of networks with different widths and activations. The numerical results suggest that regularization is essential in achieving alignment, in both regression and classification tasks, for linear and nonlinear models. We implement the feedback alignment procedure in PyTorch as an extension of the autograd module for backpropagation.

\paragraph{Feedback alignment on synthetic data}

We first train two-layer networks on synthetic data, where each network $f$ shares the architecture shown in \eqref{eqn:nonlinear-network} and the data are generated by another network $f_0$ that has the same architecture but with random Gaussian weights. We present the experiments for both linear and nonlinear networks, where the activation functions are chosen to be Rectified Linear Unit (ReLU) and Hyperbolic Tangent (Tanh) for nonlinear case. We set training sample sample size to $n=50$ and the input dimension $d=150$, but vary the hidden layer width $p = 100\times 2^k$ with $k\in[7]$. During training, we take step size $\eta = 10^{-4}$ for linear networks and $\eta = 10^{-3},10^{-2}$ for ReLU and Tanh networks, respectively.


\begin{figure}[ht]
\centering
\begin{subfigure}[b]{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/df_lr_non_autograd_l2_v6.pdf}
  \caption{Alignment on linear network.}
  \label{fig:align_lr_non_autograd_l2}
\end{subfigure}\hfill
\begin{subfigure}[b]{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/df_nn_relu_autograd_l2_v6.pdf}
  \caption{Alignment on ReLU network.}
  \label{fig:align_nn_relu_autograd_l2}
\end{subfigure}\hfill
\begin{subfigure}[b]{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/df_nn_tanh_autograd_l2_v6.pdf}
  \caption{Alignment on Tanh network.}
  \label{fig:align_nn_tanh_autograd_l2}
\end{subfigure}
\medskip
\begin{subfigure}[b]{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/loss_lr_non_autograd_l2_v1.pdf}
  \caption{Loss on linear network.}
  \label{fig:loss_lr_non_autograd_l2}
\end{subfigure}\hfill
\begin{subfigure}[b]{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/loss_nn_relu_autograd_l2_v1.pdf}
  \caption{Loss on ReLU network.}
  \label{fig:loss_nn_relu_autograd_l2}
\end{subfigure}\hfill
\begin{subfigure}[b]{.33\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/loss_nn_tanh_autograd_l2_v1.pdf}
  \caption{Loss on Tanh network.}
  \label{fig:loss_nn_tanh_autograd_l2}
\end{subfigure}
\caption{Comparisons on alignment and convergence for feedback alignment algorithm with different levels of $\ell_2$ regularization. In \cref{fig:align_lr_non_autograd_l2,fig:align_nn_relu_autograd_l2,fig:align_nn_tanh_autograd_l2}, the data points represent the mean value computed across simulations, and the error bars mark the standard deviation out of $50$ independent runs. In \cref{fig:loss_lr_non_autograd_l2,fig:loss_nn_relu_autograd_l2,fig:loss_nn_tanh_autograd_l2}, we show the trajectories of the training loss for networks with $p = 3200$, and the shaded areas represent the standard deviation over $50$ independent runs. The $x$-axes on the first row and the $y$-axes on the second row are presented in a logarithmic scale.}
\label{fig:synthetic-l2}
\end{figure}

In \cref{fig:align_lr_non_autograd_l2,fig:align_nn_relu_autograd_l2,fig:align_nn_tanh_autograd_l2}, we show numerically how alignment depends on regularization and the degree of over-completeness, parameterized by the hidden layer width $p$. Alignment is measured by the cosine of the angle between the forward weights $\beta$ and backward weights $b$. We train the networks until the the loss function converges; this procedure is repeated $50$ times for each $p$ and $\lambda$. It can be observed that for all three types of networks, as $p$ increases, alignment vanishes if there is no regularization, while alignment is stably away from zero with regularization. Further, alignment grows with the level of regularization $\lambda$ for the same network. We complement the alignment plots with the corresponding loss curves, where the training loss converges slower with larger regularization. These numerical results are consistent with our theoretical statements. We note that because of the regularization, the losses cannot converge to zero, but rather converge to a positive number that is of the same order as $\lambda$.

We would like to remark that dropout, a commonly used training technique, as a form of regularization can also help the alignment between forward and backward weights when used together with feedback alignment algorithm \citep{wager2013dropout}. However, numerical results suggest that dropout regularization fails to keep the alignment from zero for networks with large hidden layer width. To the best of our knowledge, there is no theoretical result available that explains the underlying mechanism.


\paragraph{Feedback alignment on MNIST dataset.}

The training set of \texttt{MNIST} data consists of $60000$ training images and $10000$ test images with dimension $28$ by $28$. We reshape them into vectors of length $d = 784$ and normalize them by their mean and standard deviation. The network structure is $784$-$1000$-$10$ with ReLU activation at hidden layer and softmax function at output layer. During training, we choose batch size to be $600$ and step size $\eta = 10^{-2}$. The training procedure takes $300$ epochs in total for a better visualization of the results. We repeat the training for 10 times for each choice of $\lambda$.

\cref{fig:mnist} shows the performance of feedback alignment under regularization $\lambda = 0, 0.1, 0.3$. Since the output of the network is not one-dimensional, the alignment is now measured by $\cos \angle(\dbp(h),\dfa(h))$, where $\dbp(h)$ is the error signal propagated to hidden neural $h$ through forward weights $\beta$, and $\dfa(h)$ is the one through random backward weights $b$. We observe that both alignment and convergence are improved by adding regularization to the training, and increasing the $\lambda$ can further facilitate alignment but with a small sacrifice on test accuracy.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/mnist_2l_v6_horizontal.pdf}
  \caption{Comparisons on alignment and accuracy for feedback alignment algorithm with $\lambda=0,0.1,0.3$. The left figure shows alignment defined by $\cos \angle(\dbp(h),\dfa(h))$, and right figure shows the accuracy on the test set. The dashed lines and corresponding shaded areas represent the means and the standard deviations over $10$ runs with random initialization.}
  \label{fig:mnist}
\end{figure}
